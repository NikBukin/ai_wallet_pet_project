from langchain_community.llms import YandexGPT
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from pars_info import pars_news, search_active
from database.repository import Repository
from dotenv import load_dotenv
import os

# LLM –∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()
folder_id = os.getenv("FOLDER_ID_LLM")
api_key = os.getenv("API_KEY_LLM")
llm = YandexGPT(folder_id=folder_id, api_key=api_key)


# –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π
def get_news_texts(name: str, type_active: str, shortname: str) -> list:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –∏ —Å—Å—ã–ª–æ–∫ –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –∞–∫—Ç–∏–≤—É
    :param name: –ù–∞–∑–≤–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–∞
    :param type_active: –¢–∏–ø –∞–∫—Ç–∏–≤–∞
    :param shortname: –í—Ç–æ—Ä–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–∞ (—Ç–∏–∫–µ—Ä)
    :return:
    """
    if type_active == "stock_rus":
        try:
            news = pars_news.get_finam_news([name])
        except:
            news = pars_news.get_finam_news([shortname])
        return [[n["text"], n["link"]] for n in news if n["text"]]
    elif type_active in ["stock_for", "metal"]:
        try:
            news = pars_news.get_yahoo_news([name])
        except:
            news = pars_news.get_yahoo_news([shortname])
        return [[n["text"], n["link"]] for n in news if n["text"]]
    elif type_active == "cripto":
        try:
            news = pars_news.get_crypto_news([name])
        except:
            news = pars_news.get_crypto_news([shortname])
        return [[n["text"], n["link"]] for n in news if n["text"]]
    else:
        return [[]]


def llm_find_active(input_text:str, llm)->dict:
    """
    –í—ã—á–ª–µ–Ω–µ–Ω–∏–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è –∞–∫—Ç–∏–≤–∞ –ø–æ –Ω–µ—Ç–æ—á–Ω–æ–º—É –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–± –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ find_best_match_func
    """
    prompt = PromptTemplate(
        input_variables=["text"],
        template="""
–ò–∑–≤–ª–µ–∫–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞. –í—ã–≤–µ–¥–∏ –¢–û–õ–¨–ö–û –Ω–∞–∑–≤–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–∞. –ï—Å–ª–∏ –∞–∫—Ç–∏–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤—ã–≤–µ–¥–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É.

---
–ü—Ä–∏–º–µ—Ä—ã:
–¢–µ–∫—Å—Ç: "–ö–∞–∫–∏–µ –±—ã–ª–∏ –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –∞–∫—Ü–∏—è–º–∏ —Å–±–µ—Ä–±–∞–Ω–∫–∞?"
–ê–∫—Ç–∏–≤: –°–±–µ—Ä–±–∞–Ω–∫

–¢–µ–∫—Å—Ç: "–ß—Ç–æ —Å –±–∏—Ç–∫–æ–∏–Ω–æ–º?"
–ê–∫—Ç–∏–≤: bitcoin

–¢–µ–∫—Å—Ç: "–ß—Ç–æ —Å–ª—ã—à–Ω–æ –ø—Ä–æ Apple."
–ê–∫—Ç–∏–≤: Apple

–¢–µ–∫—Å—Ç: "–ù–æ–≤–æ—Å—Ç–∏ –ø–æ –∑–æ–ª–æ—Ç—É."
–ê–∫—Ç–∏–≤: –∑–æ–ª–æ—Ç–æ
---

–¢–µ–∫—Å—Ç: "{text}"
–ê–∫—Ç–∏–≤:
"""
    )
    chain = LLMChain(llm=llm, prompt=prompt, verbose=False)
    response_dict = chain.invoke({"text": input_text}, stop=["\n"])
    if isinstance(response_dict, dict) and 'text' in response_dict:
        active_name = response_dict['text'].strip()
    elif isinstance(response_dict, str):
        active_name = response_dict.strip()
    else:
        active_name = ""

    lines = active_name.split('\n')
    cleaned_active_name = ""
    for line in lines:
        if line.strip() and not line.strip().startswith(("–¢–µ–∫—Å—Ç:", "–ê–∫—Ç–∏–≤:", "–í–æ–ø—Ä–æ—Å", "–û—Ç–≤–µ—Ç")):
            cleaned_active_name = line.strip()
            break
    result = search_active.find_best_match_func(cleaned_active_name)
    return result



# –ê–Ω–∞–ª–∏–∑ –ø–æ –æ–¥–Ω–æ–º—É –∞–∫—Ç–∏–≤—É
def llm_news_analysis(name_active: str, shortname_active: str, type_active: str, llm):
    """
    –î–∞–µ—Ç –æ—Ü–µ–Ω–∫—É –∞–∫—Ç–∏–≤—É —Å –∫—Ä–∞—Ç–∫–∏–º –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–º –≤—ã–≤–æ–¥–æ–º –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π
    :param name_active: –ù–∞–∑–≤–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–∞
    :param type_active: –¢–∏–ø –∞–∫—Ç–∏–≤–∞
    :param shortname_active: –í—Ç–æ—Ä–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–∞ (—Ç–∏–∫–µ—Ä)
    :return:
    """
    prompt = PromptTemplate(
        input_variables=["name_active", "shortname_active", "news_text"],
        template="""
    –¢—ã ‚Äî –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫. –ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π, —Å—Ñ–æ—Ä–º–∏—Ä—É–π –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–≤–æ–¥ –¥–ª—è –∞–∫—Ç–∏–≤–∞ {name_active} - {shortname_active}, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞—Ö–æ–¥–∏—Ç—Å—è —É –∫–ª–∏–µ–Ω—Ç–∞ –≤ –∫–æ—à–µ–ª—å–∫–µ".
    –£–∫–∞–∂–∏ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –≤ 3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö:
    - –û–±—â–∏–π —Ç–æ–Ω (–ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π/–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π/–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π).
    - –ö—Ä–∞—Ç–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    - –î–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –¥–ª—è –ø–æ–∫—É–ø–∫–∏, –ø—Ä–æ–¥–∞–∂–∏ –∏–ª–∏ —É–¥–µ—Ä–∂–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
    
    –í–æ—Ç —Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏:
    {news_text}

    –û—Ç–≤–µ—Ç:
    """
    )
    chain = LLMChain(llm=llm, prompt=prompt, verbose=False)

    try:
        news = get_news_texts(name_active, type_active, shortname_active)
        if not news or not news[0] or not news[0][0]:
            return None, None  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º (None, None)

        news_text, link = news[0]  # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –∏ —Å—Å—ã–ª–∫—É

        # LLM –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –ë–ï–ó —Å—Å—ã–ª–∫–∏
        result = chain.run(
            name_active=name_active,
            shortname_active=shortname_active,
            news_text=news_text
        ).strip()

        return result, link  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º (—Ç–µ–∫—Å—Ç_LLM, —Å—Å—ã–ª–∫–∞)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è {name_active}: {e}")
        return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}", None


# –ò—Ç–æ–≥–æ–≤—ã–π –≤—ã–≤–æ–¥ –ø–æ –≤—Å–µ–º –∞–∫—Ç–∏–≤–∞–º
def analyze_assets_with_news(chat_id: int) -> tuple[str, dict]:
    """
    –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–æ–≤ –ø–æ –∫–∞–∂–¥–æ–π –Ω–∞–π–¥–µ–Ω–Ω–æ–π –Ω–æ–≤–æ—Å—Ç–∏ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—â–µ–≥–æ –æ—Ç—á–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∫–æ—à–µ–ª—å–∫–µ
    :param chat_id: chat_id –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –∞–∫—Ç–∏–≤–∞ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    :return:
    """
    assets = Repository.select_by_id_telebot(chat_id)
    assets = assets[['name_of_the_asset', 'second_name_of_the_asset', 'type_active']].drop_duplicates().to_dict(orient='records')

    all_analysis = {}
    news_summary = ""

    for asset in assets:
        name = asset["name_of_the_asset"]
        short = asset["second_name_of_the_asset"]
        type_act = asset["type_active"]

        analysis, link = llm_news_analysis(name, short, type_act, llm)
        if not analysis:
            continue

        news_summary += f"\n\n–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ –∞–∫—Ç–∏–≤—É *{name}*:\n{analysis}"
        all_analysis[name] = {
            "llm_result": analysis,
            "shortname_active": short,
            "type_active": type_act,
            "link": link
        }

    # üß† –§–∏–Ω–∞–ª—å–Ω—ã–π –æ–±–æ–±—â—ë–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    prompt_template_final = PromptTemplate(
        input_variables=["analysis_results"],
        template="""
–¢—ã ‚Äî –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫. –ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π, —Å—Ñ–æ—Ä–º–∏—Ä—É–π –ø–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–≤–æ–¥ –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞:".
–£–∫–∞–∂–∏ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —ç–º–æ–¥–∑–∏:
- –û–±—â–∏–π —Ç–æ–Ω –≤—Å–µ—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –≤ –æ–±—â–µ–º (–ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π/–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π/–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π). –û—Ç–¥–µ–ª—å–Ω–æ –≤—ã–¥–µ–ª–∏ –∞–∫—Ç–∏–≤—ã —Å –∫—Ä–∞–π–Ω–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–º —Ç–æ–Ω–æ–º –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏.
- –ö—Ä–∞—Ç–∫—É—é –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
- –î–∞–π –æ–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏.

–í–æ—Ç –≤—ã–∂–∏–º–∫–∏ –∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π:
{analysis_results}

–û—Ç–≤–µ—Ç:
"""
    )
    final_chain = LLMChain(llm=llm, prompt=prompt_template_final, verbose=False)
    final_summary = final_chain.run(analysis_results=news_summary).strip()

    return final_summary, all_analysis